{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# 创建 Python 虚拟环境并激活\n",
    "conda create -n vllm python=3.10\n",
    "conda activate vllm\n",
    "\n",
    "# 后续操作都在虚拟环境中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# 有梯子，用 Hugging Face（参考 https://huggingface.co/docs/huggingface_hub/cn/quick-start）\n",
    "pip install --upgrade huggingface_hub\n",
    "\n",
    "# 验证安装\n",
    "python -c \"from huggingface_hub import model_info; print(model_info('gpt2'))\"\n",
    "\n",
    "# 登录\n",
    "huggingface-cli login --token $HUGGINGFACE_TOKEN --add-to-git-credential\n",
    "\n",
    "# 下载\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "# 加载 .env 文件\n",
    "load_dotenv()\n",
    "\n",
    "# 从环境变量中获取 HUGGINGFACE_TOKEN\n",
    "token = os.environ.get('HUGGINGFACE_TOKEN')\n",
    "\n",
    "if token:\n",
    "    # 使用获取到的 token 进行登录\n",
    "    login()\n",
    "    print(\"登录成功\")\n",
    "else:\n",
    "    print(\"未找到 HUGGINGFACE_TOKEN 环境变量，请先设置该环境变量。\")\n",
    "\n",
    "# 下载模型\n",
    "from huggingface_hub import hf_hub_download\n",
    "hf_hub_download(\n",
    "    repo_id=\"bartowski/DeepSeek-R1-Distill-Qwen-32B-GGUF\",\n",
    "    filename=\"DeepSeek-R1-Distill-Qwen-32B-Q4_K_M.gguf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# 没梯子，用魔搭（参考 https://www.modelscope.cn/docs/intro/quickstart）\n",
    "pip install modelscope --upgrade\n",
    "\n",
    "# 验证安装\n",
    "python -c \"from modelscope.pipelines import pipeline;print(pipeline('word-segmentation')('今天天气不错，适合 出去游玩'))\"\n",
    "\n",
    "# 下载模型，但是魔搭上没有量化后的模型\n",
    "#modelscope download --model 'deepseek-ai/DeepSeek-R1-Distill-Qwen-32B' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# 安装 vllm，从阿里镜像装有问题，所以改回官方\n",
    "pip install vllm -i https://pypi.org/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# vllm 运行 llama.cpp 量化后的模型，参考：https://docs.vllm.ai/en/latest/features/quantization/gguf.html\n",
    "vllm serve ./DeepSeek-R1-Distill-Qwen-32B-Q4_K_M.gguf --tokenizer deepseek-ai/DeepSeek-R1-Distill-Qwen-32B --hf-config-path deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
